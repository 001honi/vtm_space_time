# environment settings
seed: 0
precision: fp16 #bf16
strategy: ddp

# data arguments
dataset: unified
task_fold: 0
num_workers: 4
global_batch_size: 1
# max_channels: 2
shot: 4
# n_buildings: -1
domains_per_batch: 1 # must be always 1 for now / hard-coded in uni-ds
eval_batch_size: 1
n_eval_batches: 10
img_size: 224
image_augmentation: True
unary_augmentation: True
binary_augmentation: True
mixed_augmentation: True
channel_idx: -1
sample_by_seq: True
sample_skip: 8

taskonomy: True
midair: False
openimages: False
unlabeled: False
uniform_task_sampling: False
task_sampling_weight: [1., 3., 3., 1.]
uniform_dataset_sampling: False
base_task: True
cont_task: True
cat_task: True
coco_real: True
midair_real: True


# model arguments
model: VTM
image_backbone: beit_base_patch16_224_in22k
label_backbone: vit_base_patch16_224
image_encoder_weights: imagenet
time_attention: True # 'False' for only space attention (VTM base model) 
n_frames: 4 # number of frames attended in time attention
drop_rate: 0.
drop_path_rate: 0.1
attn_drop_rate: 0.
n_attn_heads: 4
semseg_threshold: 0.2
channel_idx: -1
n_levels: 4
bitfit: True

# training arguments
n_steps: 300000
optimizer: adam
lr: 0.0001
lr_pretrained: 0.00001
lr_schedule: poly
lr_warmup: 5000
lr_warmup_scale: 0.
schedule_from: 0
weight_decay: 0.
lr_decay_degree: 0.9
mask_value: -1.
early_stopping_patience: -1

# logging arguments
log_dir: TRAIN
save_dir: TRAIN
load_dir: TRAIN
log_iter: 100
val_iter: 20000
save_iter: 20000
load_step: -1